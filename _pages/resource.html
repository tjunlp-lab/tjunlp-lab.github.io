---
layout: default
title: Resource
permalink: /resource/
---

<!-- 2024 Resources -->
<br><font face="verdana" size="6" color=#309657><strong>- 2024 Resources</strong></font>
<hr style="margin-top:-4px;height:1px;border:none;border-top:1px dotted #309657;" />
<ol>
  <li>
    LFED: Literary Fiction Evaluation Dataset for Large Language Models
    <ul>
      <li>dataset: <a href="https://github.com/tjunlp-lab/LFED.git">[github]</a></li>
    </ul>
  </li>
  <li>
    FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data
    <ul>
      <li>dataset: <a href="https://github.com/tjunlp-lab/FuxiTranyu">[github]</a></li>
    </ul>
  </li>
</ol>

<!-- 2023 Resources -->
<br><font face="verdana" size="6" color=#309657><strong>- 2023 Resources</strong></font>
<hr style="margin-top:-4px;height:1px;border:none;border-top:1px dotted #309657;" />
<ol>
  <li>
    M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models
    <ul>
      <li>dataset: <a href="https://github.com/tjunlp-lab/M3KE">[github]</a></li>
    </ul>
  </li>
  <li>
    Awesome LLMs Evaluation Papers ðŸ“‘
    <ul>
      <li>survey: <a href="https://arxiv.org/pdf/2310.19736">[pdf]</a></li>
      <li>papers list: <a href="https://github.com/tjunlp-lab/Awesome-Multilingual-LLMs-Papers?tab=readme-ov-file">[github]</a></li>
    </ul>
  </li>
</ol>

<!-- Corpora -->
<br><font face="verdana" size="6" color=#309657><strong>- Corpora</strong></font>
<hr style="margin-top:-4px;height:1px;border:none;border-top:1px dotted #309657;" />
<ol>
  <li>
    TGEA 2.0: A Large-Scale Diagnostically Annotated Dataset with Benchmark Tasks for Text Generation of Pretrained Language Models
    <ul>
      <li>paper: <a href="https://openreview.net/pdf?id=r2DdJQ9AJvI"> [pdf]</a></li>
      <li>dataset and code: <a href="https://github.com/tjunlp-lab/TGEA"><i class="fa fa-github fa-1x"></i></a> </li>
    </ul>
  </li>

  <li>
    BiPaR: A bilingual MRC dataset on novels [Jing et al. 2019]
    <ul>
      <li>paper: <a href="https://arxiv.org/abs/1910.05040?context=cs.CL"> [pdf]</a></li>
      <li>dataset: <a href="https://multinlp.github.io/BiPaR/">[homepage]</a></li>
      <li>code: <a href="https://github.com/sharejing/BiPaR"><i class="fa fa-github fa-1x"></i></a> </li>
    </ul>
  </li>

  <li>
    Dataset for Shallow Discourse Annotation for Chinese TED Talks.
    <ul>
      <li>paper: <a href="https://arxiv.org/abs/2003.04032"> [pdf]</a></li>
      <li>dataset: <a href="https://github.com/tjunlp-lab/Shallow-Discourse-Annotation-for-Chinese-TED-Talks">[homepage]</a></li>
    </ul>
  </li>
  <li>
    A Test Suite for Evaluating Discourse Phenomena in Document-level Neural Machine Translation.
    <ul>
      <li>paper: <a href="https://aclanthology.org/2020.iwdp-1.3"> [pdf]</a></li>
      <li>dataset: <a href="https://github.com/tjunlp-lab/Discourse-Phenomena-in-Document-level-Neural-Machine-Translation">[homepage]</a></li>
    </ul>
  </li>
  <li>
    RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling.
    <ul>
      <li>paper: <a href="https://arxiv.org/abs/2010.08738"> [pdf]</a></li>
      <li>dataset: <a href="https://github.com/terryqj0107/RiSAWOZ">[homepage]</a></li>
    </ul>
  </li>
  <li>
    TED-CDB: A Large-Scale Chinese Discourse Relation Dataset on TED Talks.
    <ul>
      <li>paper: <a href="https://aclanthology.org/2020.emnlp-main.223"> [pdf]</a></li>
      <li>dataset: <a href="https://github.com/wanqiulong0923/TED-CDB">[homepage]</a></li>
    </ul>
  </li>
  <li>
    Chinese WPLC: A Chinese Dataset for Evaluating Pretrained Language Models on Word Prediction Given Long-Range Context.
    <ul>
      <li>paper: <a href="https://aclanthology.org/2021.emnlp-main.306"> [pdf]</a></li>
      <li>dataset: <a href="https://git.openi.org.cn/PCL-Platform.Intelligence/Chinese_WPLC">[homepage]</a></li>
    </ul>
  </li>
</ol>

<!-- Codes -->
<br><font face="verdana" size="6" color=#309657><strong>- Codes</strong></font>
<hr style="margin-top:-4px;height:1px;border:none;border-top:1px dotted #309657;" />
<ul>
  <li>Lab repositories: <a href="http://github.com/tjunlp-lab"><i class="fa fa-github fa-1x"></i></a><br></li>
  <li>Reading Group Schedule: <a href="https://github.com/tjunlp-lab/TJU_MultiNLP_ReadingGroup"><i class="fa fa-github fa-1x"></i></a><br></li>
</ul>

<br>
